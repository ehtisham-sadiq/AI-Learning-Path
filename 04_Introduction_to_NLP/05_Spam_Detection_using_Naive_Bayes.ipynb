{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d162b058",
   "metadata": {},
   "source": [
    "---   \n",
    "\n",
    "<h1 align=\"center\">Spam Detection using Naïve Bayes' Classifier</h1>\n",
    "\n",
    "---\n",
    "<h3><div align=\"right\">Ehtisham Sadiq</div></h3>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b0c47d",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"900\"  src=\"images/spam-classifier.png\"  > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459729c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d91b1589",
   "metadata": {},
   "source": [
    "# Learning agenda of this notebook\n",
    "\n",
    "- Overview of Text Classification\n",
    "- From Bayes' Theorem to Naïve Bayes' Classifier\n",
    "    - Marginal Probability\n",
    "    - Independent Events and Joint Probability\n",
    "    - Dependent Events and Conditional Probability\n",
    "    - From Conditional Probability to Bayes’ Theorem\n",
    "    - Naïve Bayes' Classifier\n",
    "\n",
    "- Data Acquisition for Spam Filtering\n",
    "- Exploratory Data Analysis\n",
    "- Text Pre-Processing\n",
    "- Text Vectorization using Bag of Words (BoW)\n",
    "- Model Building (Feed Training Data to Machine Learning Model)\n",
    "- Evaluate Metrics for Classification Machine Learning Model\n",
    "- Creating a PipeLine for Predicting New Incoming Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed452ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814704c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b967b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0baa489c",
   "metadata": {},
   "source": [
    "# Download/Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "287fc790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q --upgrade pip\n",
    "!{sys.executable} -m pip install -q numpy pandas sklearn\n",
    "!{sys.executable} -m pip install -q nltk spacy gensim wordcloud textblob contractions clean-text unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60dc816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b4b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c9bc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7998b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14ef3127",
   "metadata": {},
   "source": [
    "# 1. <span style='background :lightgreen' > Overview of Text Classification</span>\n",
    "\n",
    "<img align=\"center\" width=\"300\"  src=\"images/text-classification1.png\"  > \n",
    "\n",
    "<img align=\"center\" width=\"800\"  src=\"images/text-classification.png\"  > \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa352756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58299b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0279822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cba46f5",
   "metadata": {},
   "source": [
    "# 2. <span style='background :lightgreen' > From Bayes' Theorem to Naïve Bayes' Classifier </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44764e3e",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"450\" height=\"150\"  src=\"images/prob1.png\" >\n",
    "\n",
    "## a. What is Marginal Probability?\n",
    "- Probability theory is a branch of mathematics concerned with the analysis of random phenomena, and defines the `likelihood of occurrence of an event`. \n",
    "- Probability can be defined as the ratio of the number of favorable outcomes to the total number of outcomes of an event.\n",
    "\n",
    "$$ P(\\text{event}) = \\frac{\\text{Number of favourable outcomes}}{\\text{Total outcomes in }\\Omega} $$\n",
    "\n",
    "- Marginal probability is the probability of an event irrespective of all other events.\n",
    "- The value of the probability of an event to happen can lie between 0 and 1 because the favorable number of outcomes can never cross the total number of outcomes. \n",
    "- When the probability of something approaches 1, then it means it is very likely, and when the probability of something approaches 0, then it means that it is very unlikely.\n",
    "- To understand Probability, we normally start to predict the outcomes for the `tossing of coins`, `rolling of dice`, or `drawing a card from a pack of playing cards`. Later we apply the same concepts in the domains of Artificial Intelligence and Machine Learning.\n",
    "\n",
    "<img align=\"center\" width=\"400\" height=\"200\"  src=\"images/prob.gif\"  > "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17298186",
   "metadata": {},
   "source": [
    "- **Example:**\n",
    "If we're only flipping the coin once, then there are only two possible outcomes in the sample space $\\Omega$: it will either be H or T (using set notation, we could write this as $\\Omega$ = {H, T}).\n",
    "Therefore: $$ P(H) = \\frac{1}{2} = 0.5 $$\n",
    "Equally: $$ P(T) = \\frac{1}{2} = 0.5 $$\n",
    "\n",
    "- **Example:** Consider drawing a single card from a standard deck of 52 playing cards. In this case, the number of possible outcomes in the sample space $\\Omega$ is 52. \n",
    "There is only one `ace of spades` in the deck, so the probability of drawing it is: $$ P(\\text{ace of spades}) = \\frac{1}{52} \\approx 0.019 $$\n",
    "In contrast there are four `aces`, so the probability of drawing an ace is: $$ P(\\text{ace}) = \\frac{4}{52} \\approx 0.077 $$\n",
    "\n",
    "- **Similarly:**\n",
    "$$ P(\\text{spade}) = \\frac{13}{52} = 0.25 $$\n",
    "$$ P(\\text{card}) = \\frac{52}{52} = 1 $$\n",
    "$$ P(\\text{apple}) = \\frac{0}{52} = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91da4aad",
   "metadata": {},
   "source": [
    ">- `Independent Events:` Two events are said to be independent, if probability of occurring of one event has not impact on probability of occurring of another event.\n",
    ">- `Dependent Events:` Two events are said to be dependent, if they happen one after another, and the probability of first event has an impact on the probability of the second event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3516ea7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad1a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b80040b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166d8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a2edfd0",
   "metadata": {},
   "source": [
    "## b. Independent Events and Joint Probability\n",
    "<img align=\"center\" width=\"300\"  src=\"images/joint-prob.png\"  > \n",
    "\n",
    "- Two events are said to be `independent`, if probability of occurring of one event has no impact on probability of occurring of another event. An example is rolling two dices together.\n",
    "- In order to compute the probability of two independent events, we use `joint probability`, that is equal to the product of individual probabilities of the two events.\n",
    "\n",
    "\\begin{equation}\n",
    "P(A \\cap B) \\hspace{0.2cm} = \\hspace{0.5cm} P(A) \\times P(B)\n",
    "\\end{equation}\n",
    "\n",
    "- Suppose we rolled two dices, what is the probability of getting two sixes?\n",
    "\n",
    "\\begin{equation}\n",
    "P(A \\cap B) \\hspace{0.2cm} = \\hspace{0.2cm} P(A) \\times P(B)  \\hspace{0.2cm}= \\hspace{0.2cm} \\frac{1}{6} \\times \\frac{1}{6}\\hspace{0.2cm}= \\hspace{0.2cm}0.0277\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "- **Examples:**\n",
    "- Tossing two or more coins: $\\hspace{0.2cm}P(A \\cap B) \\hspace{0.2cm} = \\hspace{0.2cm} \\frac{1}{2} \\times \\frac{1}{2}\\hspace{0.2cm}= \\hspace{0.2cm} \\frac{1}{4}$\n",
    "- Drawing two cards from a pack of playing cards with replacement: $P(A \\cap B) \\hspace{0.2cm} = \\hspace{0.2cm} \\frac{1}{52} \\times \\frac{1}{52}\\hspace{0.2cm}= \\hspace{0.2cm} \\frac{1}{2704}$\n",
    "- Owning a dog and driving a car\n",
    "- Winning the lottery and running out of milk\n",
    "- Taking a cab home and finding your favorite movie on cable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce145a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a698a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e5723c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c793c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "308c1eda",
   "metadata": {},
   "source": [
    "## c. Dependent Events and Conditional Probability\n",
    "\n",
    "<img align=\"center\" width=\"600\"  src=\"images/cond-prob2.png\"  > \n",
    "\n",
    "\n",
    "-  In case of two independent events A and B, their conditional probaility is: \n",
    "$\\hspace{0.5cm}P(A \\mid B) \\hspace{0.2cm}=\\hspace{0.2cm} P(A), \\hspace{0.5cm} and   \\hspace{0.5cm}P(B \\mid A) \\hspace{0.2cm}=\\hspace{0.2cm} P(B)\\hspace{0.5cm}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99693aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd079785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566f89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cec62da7",
   "metadata": {},
   "source": [
    "**Example 1:** What is the probability that a card drawn from a deck of playing cards is a Queen, given that it is a card of Spades?\n",
    "- Event-B: Card is a Spades (Event has already happened)\n",
    "- Event-A: Card is a Queen \n",
    "\n",
    "\\begin{equation} P(B) = \\frac{13}{52} \\end{equation}\n",
    "\\begin{equation} P(A) = \\frac{4}{52} \\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} \\hspace{0.5cm} = \\frac{P(A) \\times P(B)}{P(B)}  \\hspace{0.5cm} \\frac{\\frac{4}{52}*\\frac{13}{52}}{\\frac{13}{52}}\\hspace{0.5cm} = \\hspace{0.5cm}\\frac{1}{13}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5152d91",
   "metadata": {},
   "source": [
    "**Example 2:**\n",
    "- Consider the following two events:\n",
    "    - Event-B: Card drawn from a deck of cards is a face card (Event has already happened)\n",
    "    - Event-A: Without replacement the second card drawn from the same deck of cards is a face card\n",
    "\\begin{equation} P(B) = \\frac{12}{52} \\end{equation}\n",
    "\\begin{equation} P(A) = \\frac{11}{51} \\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} \\hspace{0.5cm} = \\frac{P(A) \\times P(B)}{P(B)}  \\hspace{0.5cm} \\frac{\\frac{11}{51}*\\frac{12}{52}}{\\frac{12}{52}}\\hspace{0.5cm} \\approx \\hspace{0.5cm} 0.216\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369cea7c",
   "metadata": {},
   "source": [
    "- **Example 3:** Consider the given table containing data aout 200 male and female birds in the zoo having brown and blue eyes. Suppose a bird is selected at random,\n",
    "\n",
    "<img align=\"right\" width=\"400\" height=\"400\"  src=\"images/cond-prob-ex.png\"  >\n",
    "\n",
    "- What is the probaility that the bird is female?\n",
    "\\begin{equation} P(\\text{female}) = \\frac{110}{200} \\end{equation}\n",
    "\n",
    "\n",
    "- What is the probaility that the bird is male with brown eyes?\n",
    "\\begin{equation}P(\\text{male with brown eyes}) \\hspace{0.2cm} = \\hspace{0.2cm} \\frac{70}{200}\\hspace{0.2cm}= \\hspace{0.2cm} \\frac{7}{20} \\end{equation}\n",
    "\n",
    "\n",
    "- What is the probaility that the bird is female given that it has brown eyes?\n",
    "\\begin{equation}P(\\text{female} \\mid \\text{brown}) \\hspace{0.2cm} = \\hspace{0.2cm} \\frac{P(\\text{female} \\cap \\text{brown})}{P(\\text{brown})}\\hspace{0.2cm} = \\hspace{0.2cm} \\frac{\\frac{100}{200}}{\\frac{170}{200}}\\hspace{0.2cm}= \\hspace{0.2cm} \\frac{10}{17} \\end{equation}\n",
    "\n",
    "\n",
    "- What is the probaility that the bird is male given that it has blue eyes?\n",
    "\\begin{equation}P(\\text{male} \\mid \\text{blue}) \\hspace{0.2cm} = \\hspace{0.2cm} \\frac{P(\\text{male} \\cap \\text{blue})}{P(\\text{blue})}\\hspace{0.2cm} = \\hspace{0.2cm} \\frac{\\frac{20}{200}}{\\frac{30}{200}}\\hspace{0.2cm}= \\hspace{0.2cm} \\frac{2}{3} \\end{equation}\n",
    "\n",
    "- What is the probaility that the bird has blue eyes given that it is female?\n",
    "\\begin{equation}P(\\text{blue} \\mid \\text{female}) \\hspace{0.2cm} = \\hspace{0.2cm} \\frac{P(\\text{blue} \\cap \\text{female})}{P(\\text{female})}\\hspace{0.2cm} = \\hspace{0.2cm} \\frac{\\frac{10}{200}}{\\frac{110}{200}}\\hspace{0.2cm}= \\hspace{0.2cm} \\frac{1}{11} \\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc6f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc2b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5bd254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124737d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cb8d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae11a3cc",
   "metadata": {},
   "source": [
    "## d. From Conditional Probability to Bayes’ Theorem\n",
    "- **Bayes' Theorem** (by Thomas Bayes), is a way of calculating a conditional probability without the joint probability.\n",
    "- To calculate the probability of event A to occur, given that event B has already occurred, we can use the following **Conditional Probability** formula:\n",
    "\n",
    "\\begin{equation}\n",
    "    P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} \\hspace{0.5cm} ------(i)\n",
    "\\end{equation}\n",
    "\n",
    "- Similarly, to calculate the probability that event B occurs, given that event A has already occurred, we can use the same formula, only this time changing out the denominator as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "    P(B \\mid A) = \\frac{P(B \\cap A)}{P(A)} \\hspace{0.9cm} OR \\hspace{0.9cm}  P(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} \\hspace{0.5cm}------(ii)\n",
    "\\end{equation}\n",
    "\n",
    "- Multiplying both sides of equation $(i)$ by $P(B)$ gives us:\n",
    "\n",
    "\\begin{equation}\n",
    "    P(A \\mid B) * P(B) = P(A \\cap B) \\hspace{0.5cm} ------(iii)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- Similarly, multiplying both sides of equation $(ii)$ by $P(A)$ gives us:\n",
    "\n",
    "\\begin{equation}\n",
    "    P(B \\mid A) * P(A) = P(A \\cap B) \\hspace{0.5cm} ------(iv)\n",
    "\\end{equation}\n",
    "\n",
    "- Equating equations $(iii)$ and $(iv)$, we get:\n",
    "\n",
    "\\begin{equation}\n",
    "P(A \\mid B) * P(B) \\hspace{0.5cm} = \\hspace{0.5cm}  P(B \\mid A) * P(A)  \\hspace{0.5cm}\n",
    "\\end{equation}\n",
    "\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    P(A \\mid B) \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{P(A) * P(B \\mid A)}{P(B)}, \\hspace{0.5cm} P(B)\\neq 0 \\hspace{0.5cm} ------(v)\n",
    "\\end{equation}\n",
    "\n",
    "- Where:\n",
    "    >- P(A|B) is `Posterior Probability`: Probability of an event that is calculated after all the information related to the event has been accounted for. (Also known as conditional probability).\n",
    "        >- P(A) is `Prior Probability`: Probability of an event that is calculated before considering the new information obtained.\n",
    "    >- P(B|A) is `Liklihood`: Reverse of the posterior probability.\n",
    "    >- P(B) is also known as normalization constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85add2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dbb6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b342bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a47c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2105cf1",
   "metadata": {},
   "source": [
    "- **Example 1:** What is the probability that a card drawn from a deck of playing cards is a Queen (Q), given that it is a card of Spades (S)?\n",
    "   \n",
    "$ \\hspace{0.9cm} P(Q) = \\frac{4}{52} , \\hspace{0.9cm} P(S) = \\frac{13}{52}, \\hspace{0.9cm} P(S \\mid Q) = \\frac{1}{4}, \\hspace{0.9cm} P(Q \\mid S) = \\hspace{0.2cm}? $\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    P(Q \\mid S) \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{P(Q) * P(S \\mid Q)}{P(S)}\\hspace{0.5cm}\\frac{\\frac{4}{52} * \\frac{1}{4}}{\\frac{13}{52}}\\hspace{0.5cm} = \\hspace{0.5cm}\\frac{1}{13}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc27e62",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- **Example 2:** In a school 60% of boys play football (F) and 36% of boys play cricket (C). The percentage of boys who play cricket given that they also play football is 40%. What is the percentage of those who play football given that they also play cricket?\n",
    "\n",
    "$ \\hspace{0.9cm} P(F) = 0.6 , \\hspace{0.9cm} P(C) = 0.36 , \\hspace{0.9cm} P(C \\mid F) = 0.4, \\hspace{0.9cm} P(F \\mid C) = \\hspace{0.2cm}? $\n",
    "\n",
    "\\begin{equation}\n",
    "    P(F \\mid C) \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{P(F) * P(C \\mid F)}{P(C)} \\hspace{0.5cm}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    P(F \\mid C) \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{0.4 * 0.6}{0.36} \\hspace{0.5cm}= \\hspace{0.5cm} \\frac{4}{6} \n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc094351",
   "metadata": {},
   "source": [
    "- **Example 3:** In College of Arts and Design, 40% of girst like music (M), and 24% of girls like dance (D). The percentage of girls who like dance given that they also like music is 30%. What is the probability of girls who like music given they also like dance?\n",
    "\n",
    "$ \\hspace{0.9cm} P(M) = 0.4 , \\hspace{0.9cm} P(D) = 0.24 , \\hspace{0.9cm} P(D \\mid M) = 0.3, \\hspace{0.9cm} P(M \\mid D) = \\hspace{0.2cm}? $\n",
    "\n",
    "\\begin{equation}\n",
    "    P(M \\mid D) \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{P(M) * P(D \\mid M)}{P(D)} \\hspace{0.5cm}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    P(M \\mid D) \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{0.3 * 0.4}{0.24} \\hspace{0.5cm}= \\hspace{0.5cm} \\frac{1}{2} \n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5985520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ce559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d6bdf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5e59de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38531140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdcc39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f7c5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db2ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8e653ca",
   "metadata": {},
   "source": [
    "## e. Naïve Bayes' Classifier\n",
    "- The Naïve Bayes' (NB) is a probabilistic machine learning algorithm that use Bayes’ Theorem for supervised machine learning classification. This algorithm makes an assumption that all the input features are `independent` to eachother and make `equal` contribution to the output label.\n",
    "<br>\n",
    "<img align=\"right\" width=\"300\" height=\"200\"  src=\"images/nb-classifier-types.jpg\"  > \n",
    "\n",
    "- There are three types of Naïve Bayes model under the scikit-learn library:\n",
    "    - **Bernoulli Naïve Bayes' (`BernoulliNB`):** It is used when all the input features are binary such that they take only two values. Means 0s can represent “word does not occur in the document” and 1s as \"word occurs in the document\"\n",
    "    - **Multinomial Naïve Bayes' (`MultinomialNB`):** It is used when all the input features are discrete having integer values. For example, frequency of occurrences of a term/word in a document.The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). However, in practice, fractional counts such as tf-idf may also work.\n",
    "    - **Gaussian Naïve Bayes' (`GaussianNB`):** It is used when the input features are continuous values (age, distance, inflation etc), whose probabilities can be modeled using a Gaussian/Normal distribution. \n",
    " \n",
    "- The output labels can be:\n",
    "    - **Binary:** Assign observation to one of two groups(yes/no, sick/healthy, long/short, true/false) Example is distinguishing spam and ham emails\n",
    "    - **Multinomial:** Assign observation to one of N groups (happy, sad, anger, joy, surprise, fear) Example is sentiment analysis of a tweet text to e happy, sad, angery, joyful, surprise, fear, .... Another example can be given an image and you classify it as an apple, banana, orange, mango,....\n",
    "    - **Ordinal:** Assign observation to one of N ordered groups (baby, child, teen, adult, elder, old) Example is given a text and you want to know if it is written by a baby, child, teen, adult, elder, old,...\n",
    "    - **Multiclass:** Assign observation to K of N groups. Assigning more than one label to an observation e.g.,  (happy, baby), (sad, child), (angry, adult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1505c29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7eb54d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb9c5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ac3afdb",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"400\" height=\"400\"  src=\"images/nb-ex1.png\"  >\n",
    "\n",
    "### (i) Example 1:\n",
    "\n",
    "- **Example (One input Feature and one output label):** Based on the data in this table. Determine given a new fruit of green color, what type of fruit it is?\n",
    "<br><br><br><br>\n",
    "- Probability of the fruit being `orange` given that its color is green:\n",
    "\\begin{equation}\n",
    "    P(y=orange \\mid X=green) \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{P(y=orange) * P(X=green \\mid y=orange)}{P(X=green)} \\hspace{0.5cm}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    P(y=orange \\mid X=green) \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{\\frac{46}{100} * \\frac{6}{46}}{\\frac{26}{100}} \\hspace{0.5cm}= \\hspace{0.5cm} \\frac{6}{26} \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "- Probability of fruit being `apple` given that its color is green:\n",
    "\\begin{equation}\n",
    "    P(y=apple \\mid X=green) \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{P(y=apple) * P(X=green \\mid y=apple)}{P(X=green)} \\hspace{0.5cm}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    P(y=apple \\mid X=green) \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{\\frac{54}{100} * \\frac{20}{54}}{\\frac{26}{100}} \\hspace{0.5cm}= \\hspace{0.5cm} \\frac{20}{26} \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- **Since  $\\hspace{0.3cm}P(y=apple \\mid X=green) \\hspace{0.1cm} \\gt \\hspace{0.1cm} P(y=orange \\mid X=green),\\hspace{0.3cm}$ therefore, we classify the fruit given that its color is green is an apple**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a537a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bfe37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8f738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e5a7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a60ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b285a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d622c98a",
   "metadata": {},
   "source": [
    "### (ii) Naïve Bayes' Classifier with Multiple Input Features\n",
    " \n",
    "- Consider data set having `n` features represented by $X = x_1, x_2, x_3, ... x_n$ and one output label is y. The full Naïve Bayes' Model can now be written as:\n",
    "\n",
    "\\begin{equation}\n",
    "    P(y \\mid X_i) \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{P(y) * P(X_i \\mid y)}{P(X_i)}\\hspace{0.5cm}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    P(y \\mid x_1,x_2,x_3,...x_n) \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{P(y) * P(x_1 \\mid y) * P(x_2 \\mid y) * P(x_3 \\mid y) ... * P(x_n \\mid y)}{P(x_1)*P(x_2)*P(x_3) ... *P(x_n)}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- For all entries in the dataset, the denominator does not change, it remains static. Therefore, the denominator can be removed and proportionality can be injected.\n",
    "\\begin{equation}\n",
    "   P(y \\mid x_1,x_2,x_3,...x_n)  \\hspace{0.5cm} \\propto \\hspace{0.5cm} P(y) * P(x_1 \\mid y) * P(x_2 \\mid y) * P(x_3 \\mid y) ... * P(x_n \\mid y)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "   P(y \\mid x_1,x_2,x_3,...x_n)  \\hspace{0.5cm} \\propto \\hspace{0.5cm} P(y) * \\prod_{i = 1}^{n} P(x_i \\mid y)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- In our case, the output variable (y) has only two outcomes (positive or negative). So we will compute the probability of all these features being positive as well as the probability of all these features being negative. Whatever, probability is larger is our output label.\n",
    "\n",
    "\\begin{equation}\n",
    "    P(y \\mid x_1,x_2,x_3,...x_n)  \\hspace{0.5cm} \\propto \\hspace{0.5cm} argmax_y P(y) * \\prod_{i = 1}^{n} P(x_i \\mid y)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b386e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50abb76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d4f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91948548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7769d9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a910436",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"400\"  src=\"images/nbdata.png\"  > \n",
    "\n",
    "### (iii) Example 2:\n",
    "- Let the vector $X_i$ represents the input features:\n",
    "    - $X_1$ = Outlook\n",
    "    - $X_2$ = Temperature\n",
    "    - $X_3$ = Humidity\n",
    "\n",
    "- And label y represent the ouput\n",
    "- Writing the numerator of Naive Bayes' classifier as a series of products of conditional probabilities:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    P(y \\mid x_1,x_2,x_3)  \\hspace{0.5cm} = \\hspace{0.5cm} argmax_y P(y) * \\prod_{i = 1}^{3} P(x_i \\mid y)\\hspace{2cm}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "   P(y \\mid x_1,x_2,x_3)  \\hspace{0.5cm} = \\hspace{0.5cm} P(y) * P(x_1 \\mid y) * P(x_2 \\mid y) * P(x_3 \\mid y))\n",
    "\\end{equation}\n",
    "<br><br><br>\n",
    "**Prediction:** `Let us assume that on a particular day the outlook is coludy, temperature is cool and humidity is normal. Predict if it will rain on that day?`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dce49c1",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"300\"  src=\"images/freq-tables.png\"  > \n",
    "<br><br><br>\n",
    "$P(y=yes \\mid x_1=cloudy,x_2=cool,x_3=normal) \\hspace{0.5cm}$\n",
    "<br><br>\n",
    "\\begin{equation}\n",
    "\\hspace{1cm}=\\hspace{0.5cm}P(y=yes)*P(x_1=cloudy|y=yes)*P(x_2=cool|y=yes)*P(x_3=normal|y=yes)\n",
    "\\end{equation}<br>\n",
    "\\begin{equation}\n",
    "\\hspace{1cm}=\\hspace{0.5cm}\\frac{6}{15}*\\frac{5}{6}*\\frac{4}{6}*\\frac{2}{6}\\hspace{0.5cm}=\\hspace{0.5cm}\\frac{240}{3240}\\hspace{0.5cm}=\\hspace{0.5cm}0.07407\\hspace{7.2cm}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "$P(y=no \\mid x_1=cloudy,x_2=cool,x_3=normal) \\hspace{0.5cm}$\n",
    "<br><br>\n",
    "\\begin{equation}\n",
    "\\hspace{1cm}=\\hspace{0.5cm}P(y=no)*P(x_1=cloudy|y=no)*P(x_2=cool|y=no)*P(x_3=normal|y=no)\n",
    "\\end{equation}<br>\n",
    "\\begin{equation}\n",
    "=\\hspace{0.5cm}\\frac{9}{15}*\\frac{3}{9}*\\frac{2}{9}*\\frac{2}{9}\\hspace{0.5cm}=\\hspace{0.5cm}\\frac{108}{10935}\\hspace{0.5cm}=\\hspace{0.5cm}0.00988\\hspace{5.2cm}\n",
    "\\end{equation}\n",
    "\n",
    "<br><br><br>\n",
    "- **Since the probability for $y=yes$ is more therefore we predict that it will rain**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3807793f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ef45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8920e2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa0dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e8daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe1e182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e9f3dce",
   "metadata": {},
   "source": [
    "### (iv) Example 3:\n",
    "- **Given a Labeled Toy Data Set, Calculate Prior probability of output label (positive and negative):**\n",
    "\n",
    "<img align=\"center\" width=\"500\"  src=\"images/nb-nlp.png\"  > \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d83299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95de7d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0211948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572015ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af435dd6",
   "metadata": {},
   "source": [
    "- **Calculate the Word Count, Conditional Probabilities and perform Laplace Smoothing:**\n",
    "\n",
    "<img align=\"center\" width=\"800\"  src=\"images/nb-nlp3.png\"  > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f8279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6b23ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3f2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54645dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8bbc041",
   "metadata": {},
   "source": [
    "<h3 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">I am playing cricket and happy.</h3>\n",
    "    \n",
    "\\begin{equation}\n",
    "    P(y \\mid x_1,x_2,x_3,...x_n)  \\hspace{0.5cm} = \\hspace{0.5cm} argmax_y P(y) * \\prod_{i = 1}^{n} P(x_i \\mid y)\\hspace{2cm}\n",
    "\\end{equation}\n",
    "<br><br>\n",
    "\n",
    "$P(y=+ \\mid x_1=I,x_2=am,x_3=playing, x_4=cricket, x_5=happy) \\hspace{0.5cm}$\n",
    "<br><br>\n",
    "\\begin{equation}\n",
    "= P(+) * P(I|+) * P(am|+) * P(playing|+) * P(cricket|+) * P(happy|+)\n",
    "\\end{equation}<br>\n",
    "\\begin{equation}\n",
    "\\hspace{4.8cm}=\\hspace{0.5cm}0.5*0.19*0.19*0.10*0.10*0.14\\hspace{0.5cm}=\\hspace{0.5cm}0.00002527\\hspace{7.2cm}\n",
    "\\end{equation}\n",
    "\n",
    "    \n",
    "<br><br>\n",
    "\n",
    "$P(y=- \\mid x_1=I,x_2=am,x_3=playing, x_4=cricket, x_5=happy) \\hspace{0.5cm}$\n",
    "<br><br>\n",
    "\\begin{equation}\n",
    "= P(-) * P(I|-) * P(am|-) * P(playing|-) * P(cricket|-) * P(happy|-)\n",
    "\\end{equation}<br>\n",
    "\\begin{equation}\n",
    "\\hspace{4.8cm}=\\hspace{0.5cm}0.5*0.19*0.19*0.10*0.10*0.10\\hspace{0.5cm}=\\hspace{0.5cm}0.00001805\\hspace{7.2cm}\n",
    "\\end{equation}\n",
    "\n",
    "<br><br><br>\n",
    "- **Since the probability for $y=+$ is more therefore we classify that the given document belong to Positive class**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb86253c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fff50402",
   "metadata": {},
   "source": [
    "<h3 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\">I am playing cricket and not sad.</h3>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee31807b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab7d081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29679820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b02ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78093867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff75a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02853751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be1421c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f56fc8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27aa0129",
   "metadata": {},
   "source": [
    "# 3. <span style='background :lightgreen' > Data Acquisition for Spam Filtering </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad57e7d5",
   "metadata": {},
   "source": [
    "## a. Download Dataset\n",
    "- SMS Spam Collection Dataset available at UCI repository: https://archive-beta.ics.uci.edu/ml/datasets/sms+spam+collection\n",
    "- The dataset contains text of 5572 SMS message, labeled as ham or spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ed4bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat datasets/smsspamcollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052ebf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783f1119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dd869b1",
   "metadata": {},
   "source": [
    "## b. Load Downloaded Dataset (`smsspamcollection`) in Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e48efe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e750032",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbb5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/tweet_emotions.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4925ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('tweet_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b1d3e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'sentiment':'label','content':'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9fa983",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.label[2])\n",
    "print(df.text[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe29f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.label[20])\n",
    "print(df.text[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a826081a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa7459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf846e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b363f46c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636dac74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efbe41b1",
   "metadata": {},
   "source": [
    "## c. Add Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7768e242",
   "metadata": {},
   "source": [
    "### (i) Length of Characters in Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a959da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new feature containing length of characters in text messages\n",
    "df['length'] = df['text'].apply(len)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe7c69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bae34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "245eb4c8",
   "metadata": {},
   "source": [
    "### (ii) Count of Punctuations in Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87869476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def count_punc(mystr):\n",
    "    return len([c for c in mystr if c in string.punctuation])\n",
    "\n",
    "df['punc'] = df['text'].apply(lambda x: count_punc(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will return all the punctuation marks\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f32b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5bba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f3287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd066cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9985a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce62cdd2",
   "metadata": {},
   "source": [
    "## d. Save the updated Dataframe in a New CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b67499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the resulting datafrrame to a new csv file\n",
    "df.to_csv('datasets/sms1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6ac9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee8332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028db713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6e006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "225725f8",
   "metadata": {},
   "source": [
    "# 4. <span style='background :lightgreen' > Exploratory Data Analysis </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5a98b3",
   "metadata": {},
   "source": [
    "## a. Load Updated Dataset (`sms1.csv`) in Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e42d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/sms1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d21b9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe30da36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4039c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a968d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6befa309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "952d58c6",
   "metadata": {},
   "source": [
    "## b. Locate and Handle NULL Values (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c66f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbbd2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac57b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a71c7a",
   "metadata": {},
   "source": [
    ">- We can use `df.dropna(axis=0, how='any', inplace=True)` method to drop the rows having NA in any of the column\n",
    ">- We can use `df.fillna(value, method, inplace=True)` method, where `value` or `method` argument specify the new value or the method to use to replace the missing values (`ffill(), bfill()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ff6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d4056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08b3897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf31b73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce85a9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b29abcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38831518",
   "metadata": {},
   "source": [
    "## c. Visualize the Count of Two Target Classes (HAM and SPAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb871a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many ham and spam samples we have in our dataframe\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ebef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized value counts\n",
    "df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca44024",
   "metadata": {},
   "source": [
    ">- The dataset contains 4825 ham and 747 spam messages.\n",
    ">- Seeing the count of positive and negative messages, it appears that the dataset is not very much balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a809239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.catplot(y ='label',kind='count', data = df);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdc8638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ce69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a633efb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ffaf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b83ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8482caf6",
   "metadata": {},
   "source": [
    "## d. Visualize Length of Text in HAM and SPAM Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a95c81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe containing only ham messages\n",
    "df_ham  = df[df['label'] == 'ham'].copy()\n",
    "#Create a dataframe containing only spam messages\n",
    "df_spam = df[df['label'] == 'spam'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae61bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde49cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of length of text in ham messages\n",
    "sns.displot(x= 'length', data=df_ham, kind='hist', bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7248ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of length of text in spam messages\n",
    "sns.displot(x= 'length', data=df_spam, kind='hist', bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9094abe8",
   "metadata": {},
   "source": [
    ">- Looks like spam messages are generally longer than ham messages.\n",
    ">- Bulk of ham has length below 100, for spam it is above 100.\n",
    ">- Can this feature be used for classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c1bf27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b0c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d7fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2edf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1d0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f367efbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb9d7c5a",
   "metadata": {},
   "source": [
    "## e. Visualize Punctuation Count in HAM and SPAM Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61fedbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of punctuation count of ham messages\n",
    "sns.displot(x= 'punc', data=df_ham, kind='hist', bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c01fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of punctuation count of spam messages\n",
    "sns.displot(x= 'punc', data=df_spam, kind='hist', bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb5ce7",
   "metadata": {},
   "source": [
    ">- Looks like spam messages have far less number of punctuations\n",
    ">- Can this feature be used for classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f8f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a4fa00a",
   "metadata": {},
   "source": [
    "## f. Word Cloud of HAM vs SPAM\n",
    "- Word Cloud is a data visualization technique used for representing text data in which the size of each word indicates its frequency or importance. Significant textual data points can be highlighted using a word cloud. Word clouds are widely used for analyzing data from social network websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "80bc6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def show_wordcloud(data_spam_or_ham, title):\n",
    "    text = ' '.join(data_spam_or_ham['text'].astype(str).tolist())\n",
    "    stopwords = set(wordcloud.STOPWORDS)\n",
    "    \n",
    "    fig_wordcloud = wordcloud.WordCloud(stopwords=stopwords,background_color='lightgrey',\n",
    "                    colormap='viridis', width=800, height=600).generate(text)\n",
    "    \n",
    "    plt.figure(figsize=(10,7), frameon=True)\n",
    "    plt.imshow(fig_wordcloud)  \n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=20 )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6361b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(df_spam, \"Spam messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6864e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(df_ham, \"Ham messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93921607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cf27e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14298b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f405b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2264e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff012358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32226b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deb98c5b",
   "metadata": {},
   "source": [
    "# 5. <span style='background :lightgreen' > Text Pre-Processing </span>\n",
    "<img align=\"center\" width=\"600\"  src=\"images/preprocessing.png\"  > "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5ff758",
   "metadata": {},
   "source": [
    "## a. Load Updated Dataset (`sms1.csv`) in Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"datasets/sms1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5622c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d65c436",
   "metadata": {},
   "source": [
    "## b. Basic Preprocessing, tokenization, stopword removal and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "30a00e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import contractions\n",
    "from cleantext import clean\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "wn = WordNetLemmatizer()\n",
    "\n",
    "def text_preprocessing(mystr):\n",
    "    mystr = mystr.lower()                                               # case folding\n",
    "    mystr = re.sub('\\w*\\d\\w*', '', mystr)                               # remove digits\n",
    "    mystr = re.sub('\\n', ' ', mystr)                                    # replace new line characters with space\n",
    "    mystr = re.sub('[‘’“”…]', '', mystr)                                # removing double quotes and single quotes\n",
    "    mystr = re.sub('<.*?>', '', mystr)                                  # removing html tags \n",
    "    mystr = re.sub(r'\\[.*?\\]', '', mystr)                               # remove text in square brackets\n",
    "    mystr = re.sub('https?://\\S+|www.\\.\\S+', '', mystr)                 # removing URLs\n",
    "    mystr = re.sub('\\n', ' ', mystr)                                    # replace new line characters with space\n",
    "    mystr = clean(mystr, no_emoji=True)                                 # remove emojis\n",
    "    mystr = ''.join([c for c in mystr if c not in string.punctuation])  # remove punctuations\n",
    "    mystr = ' '.join([contractions.fix(word) for word in mystr.split()])# expand contractions\n",
    "    \n",
    "    tokens = word_tokenize(mystr)                                       # tokenize the string\n",
    "    mystr = ''.join([c for c in mystr if c not in string.punctuation])  # remove punctuations\n",
    "    tokens = [token for token in tokens if token not in stop_words]     # remove stopwords\n",
    "#   tokens = [ps.stem(token) for token in tokens]                       # stemming\n",
    "    tokens = [wn.lemmatize(token) for token in tokens]                   # lemmatization\n",
    "    new_str = ' '.join(tokens)\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cfe37607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install cleantext\n",
    "# text_preprocessing(df.text[3])\n",
    "import re\n",
    "def clean_text(text):\n",
    "#     removing the @mentions\n",
    "    text = re.sub(r\"@\\w+|#\\w+\", \"\", text)\n",
    "    \n",
    "#     removing # hashtages from text\n",
    "    text = re.sub(r\"#\",\"\", text)\n",
    "    \n",
    "#     removing RT from text\n",
    "    text = re.sub(r\"RT[\\s]+\",\"\", text)\n",
    "    \n",
    "#     removing hyperlinks from text\n",
    "    text = re.sub(r\"\\w+:\\/\\/\\S+\",\"\", text)\n",
    "    \n",
    "#     removing punctuation from the text\n",
    "    text = re.sub(r\"[^a-zA-Z]\",\" \", text)\n",
    "    \n",
    "#     convert text into lowercase\n",
    "    text.lower()\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dc1fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text.apply(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e779207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['text'].apply(lambda x: clean_text(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a2fdef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb125a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2eb7bd84",
   "metadata": {},
   "source": [
    "## c. Verification of Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1bbec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bbfede",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['processed_text'][20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6f546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90818418",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['processed_text'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff83616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e21f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366adcdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83042fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ef073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffef8c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c92a283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea289b39",
   "metadata": {},
   "source": [
    "# 6. <span style='background :lightgreen' > Text Vectorization using Bag of Words (BoW)</span>\n",
    "- Frequency or statistical based approaches\n",
    "    - Label Encoding\n",
    "    - One-Hot encoding\n",
    "    - Bag of words\n",
    "    - Bag of n-grams\n",
    "    - TF-IDF\n",
    "- Prediction based approaches (Embeddings)\n",
    "    - Word2Vec — From Google\n",
    "    - Fast text — From Facebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32865a36",
   "metadata": {},
   "source": [
    "## a. Recap of BoW:\n",
    "- Bag of Words (BoW) is the most basic strategy for converting a text document into numbers, which specifies the presence/count of a word/n-grams in a vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7cc48c",
   "metadata": {},
   "source": [
    "**Option 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8cf6ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer() \n",
    "bow = cv.fit_transform(df['processed_text'])  # generates vocabulary dictionary and returns a DTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab6232",
   "metadata": {},
   "source": [
    "**Option 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "452c7665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(preprocessor=clean_text) \n",
    "bow = cv.fit_transform(df['text'])  # generates vocabulary dictionary and returns a DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b445602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f2739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a68ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32226cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930bafc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661dd3e",
   "metadata": {},
   "source": [
    ">- The DTM contains 5572 rows as there are 5572 messages/sms\n",
    ">- The DTM contains 7605 columns as there are 7605 unique words in the vocabulary of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc21c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since bow is a sparse matrix, so to change it to a dense matrix or array we can use the numpy toarray() method\n",
    "#bow.toarray()\n",
    "bow.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d36d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e0eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6444d2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aa5b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0029a8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1dd7387",
   "metadata": {},
   "source": [
    "## b. Understand the sparsity of the resulting Document-Term-Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fec413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total count of cells are:\n",
    "total_cells = bow.shape[0] * bow.shape[1]\n",
    "total_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total count of non-zero cells are:\n",
    "nonzero_cells = bow.nnz\n",
    "nonzero_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d3424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of non-zero values in the document term matrix are:\n",
    "percentage = (nonzero_cells/total_cells)*100\n",
    "percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7acb11",
   "metadata": {},
   "source": [
    ">- The DTM contains over `42 Million` cells, out of which just `42 K` contains non-zero values. \n",
    ">- So 99.9% cells contains a zero value.\n",
    ">- In order to save memory space and speed up algebraic operations, we use sparse representation of matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9055da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_preprocessing(df.iloc[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e738552",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.content.apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845f23c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fce909a",
   "metadata": {},
   "source": [
    "## c. Let us check out and understand BoW vector representation of  a specific sms message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2420cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.text[9])\n",
    "print(\"\\n\",df['processed_text'][9])\n",
    "print(\"\\n\",df['label'][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bba759",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f4b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow[9].nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2582b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bow[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ebe6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df59632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49cddcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec145a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45b739be",
   "metadata": {},
   "source": [
    "## d. View the Document-Term-Matrix in a Pandas Dataframe\n",
    "- You may opt not to save it on disk, rather the sparse matrix representation that is already there in the bow variable to proceed further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707da3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dtm = pd.DataFrame(data=bow.todense())\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ae726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d96cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c47245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0cd4c0d",
   "metadata": {},
   "source": [
    "# 7. <span style='background :lightgreen' > Model Building (Feed Training Data to Machine Learning Model) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66edb570",
   "metadata": {},
   "source": [
    "## a. Choose Machine Learning Model\n",
    "We can use any of the following machine learning models for classification problems:\n",
    "- `Naive Bayes`\n",
    "- `Logistic Regression`\n",
    "- `Support Vector Machine`\n",
    "- `K-Nearest Neighbours`\n",
    "- `Decision Tree Classifier`\n",
    "- `Random Forest Classifier`\n",
    "- `XGBoost Classifier` \n",
    "- `AdaBoost Classifier`  \n",
    "\n",
    "### Naive Bayes Classifier\n",
    "- The Naïve Bayes' (NB) is a probabilistic machine learning algorithm that use Bayes’ Theorem for supervised machine learning classification. This algorithm makes an assumption that all the input features are `independent` to eachother and make `equal` contribution to the output label.\n",
    "<br>\n",
    "<img align=\"right\" width=\"300\" height=\"200\"  src=\"images/nb-classifier-types.jpg\"  > \n",
    "\n",
    "- There are three types of Naïve Bayes model under the scikit-learn library:\n",
    "    - **Bernoulli Naïve Bayes' (`BernoulliNB`):** It is used when all the input features are binary such that they take only two values. Means 0s can represent “word does not occur in the document” and 1s as \"word occurs in the document\"\n",
    "    - **Multinomial Naïve Bayes' (`MultinomialNB`):** It is used when all the input features are discrete having integer values. For example, frequency of occurrences of a term/word in a document.The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). However, in practice, fractional counts such as tf-idf may also work.\n",
    "    - **Gaussian Naïve Bayes' (`GaussianNB`):** It is used when the input features are continuous values (age, distance, inflation etc), whose probabilities can be modeled using a Gaussian/Normal distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c97a17",
   "metadata": {},
   "source": [
    ">-  Scikit-Learn is an extension of SciPy\n",
    ">- Its primary contribution is an “API for machine learning” that exposes the implementations of a wide array of model families into a single, user-friendly interface. \n",
    ">- So we can use Scikit-Learn to simultaneously train a staggering variety of models, evaluate and compare them, and then utilize the fitted model to make predictions on new data. \n",
    ">- Since Scikit-Learn provides a standardized API, this can be done with little effort and models can be prototyped and evaluated by simply swapping out a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3476c8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1419e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cd6b0e1",
   "metadata": {},
   "source": [
    "## b. Split Data for Training and Testing\n",
    "<img align=\"center\" width=\"500\"  src=\"images/img1.jpeg\"  > "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b67e835",
   "metadata": {},
   "source": [
    "#### (i) Input Features `X` and Output Label Classes `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ffdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bow\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our output label can belong to two classes ham or spam so we need to vectorize that column to zero and ones\n",
    "# This can be done using one-hot encoding\n",
    "y = df['label']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c3912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d846f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858d35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa6bfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551c295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8d95fa3",
   "metadata": {},
   "source": [
    "#### (ii) Split Data for Training and Testing\n",
    "<img align=\"left\" width=\"400\"  src=\"images/train_test_split.png\"  > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "762b5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0380ee1d",
   "metadata": {},
   "source": [
    "> The number of outputs will be equal to 2 times the number of inputs. So if you only provide an `X` input to the function, there will be two outputs (`X_train` and `X_test`). If you provide an `X` and `y` input to the function, there will be four outputs (`X_train`, `X_test`, `y_train`, and `y_test`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed9d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of Training Input Data:', X_train.shape)\n",
    "print('Size of Training Labels:', y_train.shape)\n",
    "print('\\nSize of Testing Input Data: ', X_test.shape)\n",
    "print('Size of Testing Labels: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d693e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f859340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c20dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d9566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb3c3c81",
   "metadata": {},
   "source": [
    "## c. Fit NBC Model on the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7df39196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff241507",
   "metadata": {},
   "source": [
    "> Hyperparameters are like knobs on an oven you can tune to cook your favourite dish. Check them out using `model.get_params()` method:\n",
    ">- `alpha`: float, default=1.0 Additive (Laplace/Lidstone) smoothing parameter(0 for no smoothing).\n",
    ">- `class_prior`: array-like of shape (n_classes,), default=None Prior probabilities of the classes. If specified the priors are not adjusted according to the data.\n",
    ">- `fit_prior`: bool, default=True. Whether to learn class prior probabilities or not. If false, a uniform prior will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a5e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0422bb00",
   "metadata": {},
   "source": [
    "> A machine learning model training actually creates a mathematical representation of the relationship between the input features and the target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d09fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec50a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d60cf8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc7bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a24134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfba51ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82c52961",
   "metadata": {},
   "source": [
    "# 8. <span style='background :lightgreen' > Evaluate Metrics for Classification Machine Learning Model </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9a4516",
   "metadata": {},
   "source": [
    "## a. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b17e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f9d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e93a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test.shape: \", y_test.shape)\n",
    "print(\"prediction.shape: \", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b8a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f5ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "# disp.plot();\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,13))\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "# ax.tick_params()\n",
    "disp.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f45e293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b4e4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1548a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499ee4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0eb33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3188afbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc1b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f77be1cd",
   "metadata": {},
   "source": [
    "# <h3 align=\"center\"><div class=\"alert alert-success\" style=\"margin: 10px\">The Confusion Matrix is not confusing for humans</h3>\n",
    "\n",
    "<img align=\"center\" width=\"600\"  src=\"images/cm-sms1.png\"  > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d237826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db3f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0a0f0f5",
   "metadata": {},
   "source": [
    "## b. Accuracy\n",
    "<img align=\"right\" width=\"400\"  src=\"images/cm-sms1.png\"  > \n",
    "\n",
    "- Accuracy actually answers the question: **How often is the model correct?**\n",
    "\n",
    "\\begin{equation}\n",
    "Accuracy \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{\\text{Count of correct answers of Classifier}}{\\text{Count  of all Qs asked from Classifier}}\\hspace{2cm}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "Accuracy \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{TP + TN}{TP + TN + FP + FN}\\hspace{5cm}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "Accuracy \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{1410 + 210}{1410 + 210 + 13 + 39}\\hspace{0.5cm} = \\hspace{0.5cm} \\frac{1620}{1672}\\hspace{0.5cm} = \\hspace{0.5cm} 0.9688\n",
    "\\end{equation}\n",
    "\n",
    "- So accuracy is an evaluation metric used for classification algorithms that tells us what fraction of time the classifier was correct in classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce6079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ffdee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "315c6813",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"350\"  src=\"images/accuracy-paradox2.png\"  > \n",
    "\n",
    "## c. The Accuracy Paradox\n",
    "- Accuracy does not prove to be a good evaluation metric in case of imbalance data sets; which are very common in real world scenarios.\n",
    "\n",
    "\\begin{equation}\n",
    "Accuracy \\hspace{0.2cm} = \\hspace{0.2cm} \\frac{TP + TN}{TP + TN + FP + FN}\\hspace{0.2cm} = \\hspace{0.2cm} \\frac{95 + 0}{95 + 0 + 5 + 0}\\hspace{0.2cm} = \\hspace{0.2cm} \\frac{95}{100}\\hspace{0.2cm} = \\hspace{0.2cm} 0.95\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "- So a classifier that always predicts the majority class, in highly imbalanced dataset, will always have a high accuracy score.\n",
    "- Therefore, accuracy is not a good evaluation metrics, when the goal is to discover a rare event. For example, out of all the tweets make in Pakistan in last one month, classify tweets that are made about my youtbue channel (LearnwithArif). If a classifier return False to all the tweets, the accuracy of such a classfier will be around 99.9%\n",
    "- **Conclusion:** We should not rely solely on Accuracy as a metric. This is where Precision, Recall and F1 Score comes in :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb849b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dbcde1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02767ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed2ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e829aa4d",
   "metadata": {},
   "source": [
    "## d. Precision\n",
    "- Precision actually answers the question: **When prediction is positive, how often it matches with the ground positive?**\n",
    "\n",
    "<img align=\"right\" width=\"370\"  src=\"images/cm-precision.png\"  > \n",
    "\n",
    "\\begin{equation}\n",
    "Precision \\hspace{0.1cm} = \\hspace{0.1cm} \\frac{\\text{True Positives}}{\\text{Predicted Positives}}\\hspace{0.1cm} = \\frac{TP}{TP + FP}\n",
    "\\end{equation}\n",
    "<br><br>\n",
    "- If we consider `ham` label as positive:\n",
    "\\begin{equation}\n",
    "Precision \\hspace{0.1cm} = \\hspace{0.1cm} \\frac{1410}{1410 + 13} =  \\frac{1410}{1423} = 0.9908\n",
    "\\end{equation}\n",
    "<br><br>\n",
    "- If we consider `spam` label as positive:\n",
    "\\begin{equation}\n",
    "Precision \\hspace{0.1cm} = \\hspace{0.1cm} = \\frac{210}{210 + 39} =  \\frac{210}{249} = 0.8433\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d33b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a75de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_score\n",
    "# print(precision_score(y_test, predictions, pos_label='ham'))\n",
    "# print(precision_score(y_test, predictions, pos_label='spam'))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "print(precision_score(y_test, predictions))\n",
    "print(precision_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb967ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f81114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af93c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cdce76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3629d1e2",
   "metadata": {},
   "source": [
    "## e. Recall (a.k.a Sensitivity)\n",
    "\n",
    "- Recall actually answers the question: **When ground reality is a positive, how often it is correct?**\n",
    "\n",
    "<img align=\"right\" width=\"370\"  src=\"images/cm-recall.png\"  > \n",
    "\n",
    "\\begin{equation}\n",
    "Recall \\hspace{0.1cm} = \\hspace{0.1cm} \\frac{\\text{True Positives}}{\\text{Real Positives}}\\hspace{0.1cm} = \\frac{TP}{TP + FN}\n",
    "\\end{equation}\n",
    "<br><br>\n",
    "- If we consider `ham` label as positive:\n",
    "\\begin{equation}\n",
    "Recall \\hspace{0.1cm} = \\hspace{0.1cm} \\frac{1410}{1410 + 39} =  \\frac{1410}{1449} = 0.9730\n",
    "\\end{equation}\n",
    "<br><br>\n",
    "- If we consider `spam` label as positive:\n",
    "\\begin{equation}\n",
    "Recall \\hspace{0.1cm} = \\frac{210}{210 + 13} =  \\frac{210}{223} = 0.9417\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- If Recall is high, that means the classifier is good in identifying the real patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac1f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print(recall_score(y_test, predictions, pos_label='ham'))\n",
    "print(recall_score(y_test, predictions, pos_label='spam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a1b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2852f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceafa34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b563bb44",
   "metadata": {},
   "source": [
    "## f. Limitation of Precision and Recall\n",
    "\n",
    "<img align=\"center\" width=\"900\"  src=\"images/cm-pr-lim.png\"  > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81036d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22192bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a20d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47607194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a56b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36ff1c79",
   "metadata": {},
   "source": [
    "## g. F-1 Score\n",
    "- Precision and Recall alone do not solve the Accuracy Paradox. So, we combine both these metrics to create a new metric called F1 Score, which is harmonic mean of precision and recall. \n",
    "- We use harmonic mean instead of arithmetic mean because harmonic mean punishes extreme values more. OR in simple words, the harmonic means goes to zero if either of the recall or precision ends up being zero\n",
    "\n",
    "<img align=\"right\" width=\"400\"  src=\"images/cm-sms1.png\"  > \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "F1 \\hspace{0.5cm} = \\hspace{0.5cm} \\left( \\frac{Precision^{-1} + Recall^{-1}}{2}\\right)^{-1}\\hspace{3cm}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "F1 \\hspace{0.2cm} = \\hspace{0.2cm} \\left( \\frac{\\frac{1}{P} + \\frac{1}{R}}{2}\\right)^{-1}\\hspace{0.2cm} = \\hspace{0.2cm} \\left( \\frac{2} {\\frac{1}{P} + \\frac{1}{R}}\\right)\\hspace{0.2cm} = \\hspace{0.2cm} \\left( \\frac{2PR}{P +R}\\right)\n",
    "\\end{equation}\n",
    "<br><br>\n",
    "- If we consider `ham` label as positive:\n",
    "\\begin{equation}\n",
    "F1 \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{2*0.99*0.97}{0.99+0.97} \\hspace{0.5cm}= \\hspace{0.5cm} \\frac{1.926}{0.9603} \\hspace{0.5cm}=\\hspace{0.5cm} 0.98\n",
    "\\end{equation}\n",
    "<br><br>\n",
    "- If we consider `spam` label as positive:\n",
    "\\begin{equation}\n",
    "F1 \\hspace{0.5cm} = \\hspace{0.5cm} \\frac{2*0.84*0.94}{0.84+0.94} \\hspace{0.5cm}= \\hspace{0.5cm} \\frac{1.5792}{1.78} \\hspace{0.5cm}=\\hspace{0.5cm} 0.89\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- F1 score will be high, if **both** precision and recall are high.\n",
    "- F1 score will be low, if **any** of precision or recall are low.\n",
    "\n",
    "- We use harmonic mean instead of arithmetic mean because harmonic mean punishes extreme values more. OR in simple words, the harmonic means goes to zero if either of the recall or precision ends up being zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1acd295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a851fb1f",
   "metadata": {},
   "source": [
    "> **ROC Curve:**\n",
    ">- My dear students, other than Accuracy, Precision, Recall and F1 score, there are many more metrics stemming from confusion matrix.\n",
    ">- The tradeoff between precision and recall can be understood using `Receiver Operator Characteristic (ROC) curve`, which is a plot between the false positive rate (FPR) along x-axis versus the true positive rate (TPR) along y-axis at different probability threshold values between 0.0 and 1.0. The area under the curve represents the goodness of the model. \n",
    ">- For details visit: https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92afd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505841d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5851e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fdffd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9b6d473",
   "metadata": {},
   "source": [
    "# 9. <span style='background :lightgreen' > Model Deployment</span>\n",
    "<img align=\"center\" width=\"800\"  src=\"images/deployment.png\"  > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecc2b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4f83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c69846b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf0f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d74906bd",
   "metadata": {},
   "source": [
    "## a. PipeLine  for the Multinomial Naive Bayes Classifier\n",
    "<img align=\"center\" width=\"700\"  src=\"images/nlp-pipeline-obj.png\"  > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18916563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7692f3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f34b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"datasets/tweet_emotions.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1c0679d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e0546c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ce22c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f407b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipe = Pipeline([ ('bow'  , CountVectorizer(preprocessor=clean_text)),\n",
    "                  ('model' , MultinomialNB())\n",
    "                ])\n",
    "type(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eb6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sms = [\"Good Morning Ehtisham, today is bad for me\"]\n",
    "pipe.predict(new_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa4151",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sms = [\"Call me now and get a free mobile\"]\n",
    "pipe.predict(new_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a60fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8855b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
