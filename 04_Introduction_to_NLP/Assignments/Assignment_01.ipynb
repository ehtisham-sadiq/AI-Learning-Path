{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ad7457-e6d8-44b3-8a12-db4e63550a32",
   "metadata": {},
   "source": [
    "# **Assignment 1: Exploring NLP Fundamentals and Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef63568-2081-4488-8a50-499b147a6868",
   "metadata": {},
   "source": [
    "### **Q1: NLP in the Real World**\n",
    "\n",
    "- Choose **two industries** (e.g., healthcare, finance, e-commerce, or another) and discuss one **NLP use case** for each. For each use case:  \n",
    "   - Describe the problem and how NLP can solve it.  \n",
    "   - List three challenges in applying NLP to this scenario (e.g., data availability, multilingual support, or ambiguity).  \n",
    "\n",
    "- As a data scientist, you are tasked with designing an **NLP-based chatbot** for a university.  \n",
    "   - Write the steps of the pipeline (in detail) you would follow to build the chatbot, including data collection, preprocessing, and feature extraction.  \n",
    "   - Suggest two real-world datasets you might use to train this chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11b3ac1-a7d7-4c7b-83aa-04ebc4724f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d07a0-4837-4ed4-9dce-c5079329c402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8452c12-3d5c-4cdc-afdb-d66b3416cd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d14d487-07c8-48a1-8759-7c221491bd8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "290d67f9-7334-4023-bb0f-afdac8790a4b",
   "metadata": {},
   "source": [
    "### **Q2: Practical Challenges in Language Ambiguities**\n",
    "\n",
    "- Write **Python code** to analyze the lexical ambiguity of the word \"bat\" in the following sentences. Use any pre-trained NLP library (e.g., spaCy) to determine its **Part of Speech (POS):**  \n",
    "\n",
    "\tâ€¢\tThe bat flew across the cave.\n",
    "\tâ€¢\tHe hit the ball with a bat.\n",
    "\n",
    "- Syntactic ambiguity often arises in complex sentences. Rewrite the following sentence to **resolve the ambiguity** in two different ways:  \n",
    "\n",
    ">    **I saw the man with the telescope**\n",
    "\n",
    "    \n",
    "- Semantic ambiguity can make NLP tasks difficult. Propose a strategy or algorithm to resolve semantic ambiguity in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d4372-e6e4-419a-94b7-b952fd0c768d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad06a18-842c-4606-a220-e10b37257c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422952ad-dd87-4cb0-a558-19e5c23c08be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cab5f5e-5ba2-4b71-a835-7c3f49b22deb",
   "metadata": {},
   "source": [
    "### **Q3: Advanced Text Cleaning for Social Media**\n",
    "\n",
    "Social media data is often noisy, with hashtags, mentions, and emojis.\n",
    "\n",
    "- Write a Python function that performs the following steps on a given tweet:  \n",
    "    - Removes mentions (e.g., `@username`), hashtags (e.g., `#topic`), and URLs.  \n",
    "    - Replaces emojis with their textual meaning (use the `emoji` library).  \n",
    "    - Removes stopwords using NLTK.\n",
    "\n",
    "- Use your function to preprocess the following tweet:  \n",
    "\n",
    ">   **@John I love #NLP! Check this out: https://nlp-tutorial.com ðŸ˜Š #DataScience**\n",
    "\n",
    "- Explain how this cleaned tweet can be used in a **sentiment analysis model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0793d66-af67-49c7-b0c3-9957f6801c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3faa43-8917-4bc0-a34a-524e5489dd59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f4c368b-631d-4979-adb2-87570bd1a27b",
   "metadata": {},
   "source": [
    "### **Q4: Tokenization and Real-World Text**\n",
    "\n",
    "**Tokenization** plays a critical role in dividing text into meaningful units.\n",
    "\n",
    "- Tokenize the following text into **sentences** using Python's `nltk.sent_tokenize()` and spaCy's sentence tokenizer.  \n",
    "\n",
    ">    **Dr. Smith graduated from Stanford University in 2003. He now works at Google as a Senior Data Scientist**\n",
    "\n",
    "- Tokenize the same text into **words** using:  \n",
    "    - `nltk.word_tokenize()`  \n",
    "    - spaCy's tokenizer  \n",
    "\n",
    "> **Note:** Compare the outputs. Which method handles punctuation better?\n",
    "\n",
    "- Real-world Challenge:  \n",
    "    - Explain why sentence and word tokenization can be difficult for languages like Chinese or Arabic.  \n",
    "    - Suggest an NLP library/tool that effectively handles tokenization for such languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94cbee1-df73-4bd9-86b9-64fca0f1ae78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52d59ae0-f68f-40a8-996e-c70773c820be",
   "metadata": {},
   "source": [
    "### **Q5: Stopwords and Custom Filters**\n",
    "\n",
    "**Stopwords** often reduce noise in data, but not all stopwords are irrelevant in every context.\n",
    "\n",
    "- Write a Python script to remove stopwords from the following customer review:\n",
    "  - Use NLTK's English stopword list.\n",
    "    > **The delivery was quick, and the packaging was excellent, but the product quality was poor.**\n",
    "\n",
    "- Add a custom stopword filter to remove domain-specific words like \"delivery\" and \"packaging.\" Explain why custom stopwords might be useful in specific NLP tasks.\n",
    "\n",
    "- Discuss a scenario where **keeping stopwords** (e.g., \"not\", \"but\") might be critical for the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4858ad-fc7d-4b49-91c2-effd3bce47dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43618e4c-1ae8-4ad3-967c-4fe1958f9cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf561e27-225e-4de5-9bf4-18ce1755e57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a99962-0f72-4377-9490-8bce4513b7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7e26aac-31e0-423a-a203-cd54815b850e",
   "metadata": {},
   "source": [
    "### **Q6: Creating N-Grams for Product Reviews**\n",
    "\n",
    "**N-grams** are helpful for understanding the context of text.\n",
    "\n",
    "- Define what an **n-gram** is and explain its role in capturing context.\n",
    "\n",
    "- Using Python, generate **bigrams** and **trigrams** for the following review:  \n",
    "\n",
    "    > **The product quality is amazing and works as expected.**\n",
    "\n",
    "- Use the output of your n-grams to perform a basic frequency analysis. Identify the most common bigram and trigram.  \n",
    "\n",
    "- Discuss how you would use n-grams in a **recommendation system** for e-commerce products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66200ab-8ce0-4452-8d72-0e9810e70725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbaa022-20ed-4fae-be4b-27982d332ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eab9a6a6-f2ee-42f8-9649-3207b6b95bbc",
   "metadata": {},
   "source": [
    "### **Q7: Case Study: Preprocessing Job Descriptions**\n",
    "\n",
    "Imagine you're building an NLP model to analyze job descriptions and match them with resumes.  \n",
    "\n",
    "- Create a small dataset of 5 job descriptions. Example:  \n",
    "\t> **We are looking for a data scientist with expertise in Python and SQL.**\n",
    " \n",
    "\t> **The candidate should have experience in machine learning and data visualization.**\n",
    "\n",
    "- Write a Python script to preprocess these job descriptions:  \n",
    "    - Convert text to lowercase.  \n",
    "    - Remove punctuation and stopwords.  \n",
    "    - Tokenize the text into words.  \n",
    "\n",
    "- Perform a frequency analysis on the preprocessed job descriptions. Identify the top 5 most common words.\n",
    "- **Optional:** How might preprocessing job descriptions improve the performance of a job-matching NLP model? What challenges might arise when handling multilingual job descriptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a3a24-14b3-48ea-ae99-0eadbe426374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
